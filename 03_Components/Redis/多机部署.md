- [高可用](#高可用)
  - [建立连接](#建立连接)
- [命令传播](#命令传播)
- [分摊主服务器的压力](#分摊主服务器的压力)
- [增量复制](#增量复制)
- [哨兵](#哨兵)
  - [哨兵集群组成](#哨兵集群组成)
  - [主节点故障判断](#主节点故障判断)
  - [Leader投票](#leader投票)
  - [主从故障转移](#主从故障转移)
- [集群](#集群)
  - [Hash slot](#hash-slot)
- [其他](#其他)
- [](#)

## 高可用
```shell
# 服务器 B 执行这条命令
replicaof <服务器 A 的 IP 地址> <服务器 A 的 Redis 端口号>
```
### 建立连接

![](source/%E5%BB%BA%E7%AB%8B%E8%BF%9E%E6%8E%A5.webp)
第一阶段：建立链接、协商同步

    执行了 replicaof 命令后，从服务器就会给主服务器发送 psync 命令，表示要进行数据同步。

    psync 命令包含两个参数，分别是主服务器的 runID 和复制进度 offset。

    runID，每个 Redis 服务器在启动时都会自动生产一个随机的 ID 来唯一标识自己。当从服务器和主服务器第一次同步时，因为不知道主服务器的 run ID，所以将其设置为 "?"。
    offset，表示复制的进度，第一次同步时，其值为 -1。
    主服务器收到 psync 命令后，会用 FULLRESYNC 作为响应命令返回给对方。

    并且这个响应命令会带上两个参数：主服务器的 runID 和主服务器目前的复制进度 offset。从服务器收到响应后，会记录这两个值。

    FULLRESYNC 响应命令的意图是采用全量复制的方式，也就是主服务器会把所有的数据都同步给从服务器。


第二阶段：主服务器同步数据给从服务器

    接着，主服务器会执行 bgsave 命令来生成 RDB 文件，然后把文件发送给从服务器。

    从服务器收到 RDB 文件后，会先清空当前的数据，然后载入 RDB 文件。

    这里有一点要注意，主服务器生成 RDB 这个过程是不会阻塞主线程的，因为 bgsave 命令是产生了一个子进程来做生成 RDB 文件的工作，是异步工作的，这样 Redis 依然可以正常处理命令。

    但是，这期间的写操作命令并没有记录到刚刚生成的 RDB 文件中，这时主从服务器间的数据就不一致了。

    那么为了保证主从服务器的数据一致性，主服务器在下面这三个时间间隙中将收到的写操作命令，写入到 replication buffer 缓冲区里：

    主服务器生成 RDB 文件期间；
    主服务器发送 RDB 文件给从服务器期间；
    「从服务器」加载 RDB 文件期间；

第三阶段：主服务器发送新写操作命令给从服务器

    在主服务器生成的 RDB 文件发送完，从服务器收到 RDB 文件后，丢弃所有旧数据，将 RDB 数据载入到内存。完成 RDB 的载入后，会回复一个确认消息给主服务器。

    接着，主服务器将 replication buffer 缓冲区里所记录的写操作命令发送给从服务器，从服务器执行来自主服务器 replication buffer 缓冲区里发来的命令，这时主从服务器的数据就一致了。


## 命令传播
主从服务器在完成第一次同步后，双方之间就会维护一个 TCP 连接。

后续主服务器可以通过这个连接继续将写操作命令传播给从服务器，然后从服务器执行该命令，使得与主服务器的数据库状态相同。

而且这个连接是长连接的，目的是避免频繁的 TCP 连接和断开带来的性能开销。

上面的这个过程被称为基于长连接的命令传播，通过这种方式来保证第一次同步后的主从服务器的数据一致性。


## 分摊主服务器的压力

主从服务器在第一次数据同步的过程中，主服务器会做两件耗时的操作：生成 RDB 文件和传输 RDB 文件。

主服务器是可以有多个从服务器的，如果从服务器数量非常多，而且都与主服务器进行全量同步的话，就会带来两个问题：

由于是通过 bgsave 命令来生成 RDB 文件的，那么主服务器就会忙于使用 fork() 创建子进程，如果主服务器的内存数据非大，在执行 fork() 函数时是会阻塞主线程的，从而使得 Redis 无法正常处理请求；
传输 RDB 文件会占用主服务器的网络带宽，会对主服务器响应命令请求产生影响。

解决方法:
从服务器可以有自己的从服务器，我们可以把拥有从服务器的从服务器当作经理角色，它不仅可以接收主服务器的同步数据，自己也可以同时作为主服务器的形式将数据同步给从服务器，通过这种方式，主服务器生成 RDB 和传输 RDB 的压力可以分摊到充当经理角色的从服务器。

## 增量复制
主从服务器在完成第一次同步后，就会基于长连接进行命令传播。

如果主从服务器间的网络连接断开了，那么就无法进行命令传播了，这时从服务器的数据就没办法和主服务器保持一致了，客户端就可能从「从服务器」读到旧的数据。从 Redis 2.8 开始，网络断开又恢复后，从主从服务器会采用增量复制的方式继续同步，也就是只会把网络断开期间主服务器接收到的写操作命令，同步给从服务器。


主要有三个步骤：

    从服务器在恢复网络后，会发送 psync 命令给主服务器，此时的 psync 命令里的 offset 参数不是 -1；

    主服务器收到该命令后，然后用 CONTINUE 响应命令告诉从服务器接下来采用增量复制的方式同步数据；

    然后主服务将主从服务器断线期间，所执行的写命令发送给从服务器，然后从服务器执行这些命令。


那么关键的问题来了，主服务器怎么知道要将哪些增量数据发送给从服务器呢？

答案藏在这两个东西里：

`repl_backlog_buffer`，是一个「环形」缓冲区，用于主从服务器断连后，从中找到差异的数据；
`replication offset`，标记上面那个缓冲区的同步进度，主从服务器都有各自的偏移量，主服务器使用 `master_repl_offset` 来记录自己「写」到的位置，从服务器使用 `slave_repl_offset` 来记录自己「读」到的位置。
那 `repl_backlog_buffer` 缓冲区是什么时候写入的呢？

在主服务器进行命令传播时，不仅会将写命令发送给从服务器，还会将写命令写入到 `repl_backlog_buffer` 缓冲区里，因此 这个缓冲区里会保存着最近传播的写命令。

网络断开后，当从服务器重新连上主服务器时，从服务器会通过 `psync` 命令将自己的复制偏移量 `slave_repl_offset` 发送给主服务器，主服务器根据自己的 `master_repl_offset` 和 `slave_repl_offset` 之间的差距，然后来决定对从服务器执行哪种同步操作：

如果判断出从服务器要读取的数据还在 `repl_backlog_buffer` 缓冲区里，那么主服务器将采用增量同步的方式；
相反，如果判断出从服务器要读取的数据已经不存在 `repl_backlog_buffer` 缓冲区里，那么主服务器将采用全量同步的方式。
当主服务器在 `repl_backlog_buffer` 中找到主从服务器差异（增量）的数据后，就会将增量的数据写入到 `replication buffer` 缓冲区，这个缓冲区我们前面也提到过，它是缓存将要传播给从服务器的命令。

`repl_backlog_buffer` 缓行缓冲区的默认大小是 1M，并且由于它是一个环形缓冲区，所以当缓冲区写满后，主服务器继续写入的话，就会覆盖之前的数据。因此，当主服务器的写入速度远超于从服务器的读取速度，缓冲区的数据一下就会被覆盖。

`repl_backlog_buffer` 最小的大小为`second*write_size_per_second`

    `second` 为从服务器断线后重新连接上主服务器所需的平均 时间(以秒计算)。
    `write_size_per_second` 则是主服务器平均每秒产生的写命令数据量大小。
    举个例子，如果主服务器平均每秒产生 1 MB 的写命令，而从服务器断线之后平均要 5 秒才能重新连接主服务器。



## 哨兵
Redis 在 2.8 版本以后提供的哨兵（Sentinel）机制，它的作用是实现主从节点故障转移。它会监测主节点是否存活，如果发现主节点挂了，它就会选举一个从节点切换为主节点，并且把新主节点的相关信息通知给从节点和客户端。

### 哨兵集群组成

```shell
# 配置哨兵的信息 
sentinel monitor <master-name> <ip> <redis-port> <quorum>
 ```

哨兵节点之间是通过 Redis 的发布者/订阅者机制来相互发现的。

在主从集群中，主节点上有一个名为`__sentinel__:hello`的频道，不同哨兵就是通过它来相互发现，实现互相通信的。

### 主节点故障判断

哨兵会每隔 1 秒给所有主从节点发送 PING 命令，当主从节点收到 PING 命令后，会发送一个响应命令给哨兵，这样就可以判断它们是否在正常运行。
如果主节点或者从节点没有在规定的时间内响应哨兵的 PING 命令，哨兵就会将它们标记为「主观下线」。这个「规定的时间」是配置项 `down-after-milliseconds` 参数设定的，单位是毫秒。

为了减少误判的情况，哨兵在部署的时候不会只部署一个节点，而是用多个节点部署成哨兵集群（最少需要三台机器来部署哨兵集群），通过多个哨兵节点一起判断，就可以就可以避免单个哨兵因为自身网络状况不好，而误判主节点下线的情况。同时，多个哨兵的网络同时不稳定的概率较小，由它们一起做决策，误判率也能降低。

当一个哨兵判断主节点为「主观下线」后，就会向其他哨兵发起命令，其他哨兵收到这个命令后，就会根据自身和主节点的网络状况，做出赞成投票或者拒绝投票的响应。
当这个哨兵的赞同票数达到哨兵配置文件中的 `quorum` 配置项设定的值后，这时主节点就会被该哨兵标记为「客观下线」。

    例如，现在有 3 个哨兵，`quorum` 配置的是 2，那么一个哨兵需要 2 张赞成票，就可以标记主节点为“客观下线”了。这 2 张赞成票包括哨兵自己的一张赞成票和另外两个哨兵的赞成票。

    PS：quorum 的值一般设置为哨兵个数的二分之一加1，例如 3 个哨兵就设置 2。

哨兵判断完主节点客观下线后，哨兵就要开始在多个「从节点」中，选出一个从节点来做新主节点。

### Leader投票

哪个哨兵节点判断主节点为「客观下线」，这个哨兵节点就是候选者，所谓的候选者就是想当 Leader 的哨兵。

举个例子，假设有三个哨兵。当哨兵 B 先判断到主节点「主观下线后」，就会给其他实例发送 is-master-down-by-addr 命令。接着，其他哨兵会根据自己和主节点的网络连接情况，做出赞成投票或者拒绝投票的响应。

当哨兵 B 收到赞成票数达到哨兵配置文件中的 quorum 配置项设定的值后，就会将主节点标记为「客观下线」，此时的哨兵 B 就是一个Leader 候选者。

候选者会向其他哨兵发送命令，表明希望成为 Leader 来执行主从切换，并让所有其他哨兵对它进行投票。

每个哨兵只有一次投票机会，如果用完后就不能参与投票了，可以投给自己或投给别人，但是只有候选者才能把票投给自己。

那么在投票过程中，任何一个「候选者」，要满足两个条件：

第一，拿到半数以上的赞成票；
第二，拿到的票数同时还需要大于等于哨兵配置文件中的 quorum 值。
举个例子，假设哨兵节点有 3 个，quorum 设置为 2，那么任何一个想成为 Leader 的哨兵只要拿到 2 张赞成票，就可以选举成功了。如果没有满足条件，就需要重新进行选举。

这时候有的同学就会问了，如果某个时间点，刚好有两个哨兵节点判断到主节点为客观下线，那这时不就有两个候选者了？这时该如何决定谁是 Leader 呢？

    每位候选者都会先给自己投一票，然后向其他哨兵发起投票请求。如果投票者先收到「候选者 A」的投票请求，就会先投票给它，如果投票者用完投票机会后，收到「候选者 B」的投票请求后，就会拒绝投票。这时，候选者 A 先满足了上面的那两个条件，所以「候选者 A」就会被选举为 Leader。

为什么哨兵节点至少要有 3 个？

    如果哨兵集群中只有 2 个哨兵节点，此时如果一个哨兵想要成功成为 Leader，必须获得 2 票，而不是 1 票。

    所以，如果哨兵集群中有个哨兵挂掉了，那么就只剩一个哨兵了，如果这个哨兵想要成为 Leader，这时票数就没办法达到 2 票，就无法成功成为 Leader，这时是无法进行主从节点切换的。

    因此，通常我们至少会配置 3 个哨兵节点。这时，如果哨兵集群中有个哨兵挂掉了，那么还剩下两个个哨兵，如果这个哨兵想要成为 Leader，这时还是有机会达到 2 票的，所以还是可以选举成功的，不会导致无法进行主从节点切换。


quorum 的值建议设置为哨兵个数的二分之一加1，例如 3 个哨兵就设置 2，5 个哨兵设置为 3，而且哨兵节点的数量应该是奇数。


### 主从故障转移
主从故障转移操作包含以下四个步骤：

    第一步：在已下线主节点（旧主节点）属下的所有「从节点」里面，挑选出一个从节点，并将其转换为主节点。

        把网络状态不好的从节点过滤掉，并根据 优先级、复制进度、ID 号 选出新的主节点

        选好新主节点后，leader对其发送 SLAVEOF no one 命令，且哨兵 leader 会以每秒一次的频率向被升级的从节点发送 INFO 命令（没进行故障转移之前，INFO 命令的频率是每十秒一次），并观察命令回复中的角色信息，当被升级节点的角色信息从原来的 slave 变为 master 时，哨兵 leader 就知道被选中的从节点已经顺利升级为主节点了。

    第二步：让已下线主节点属下的所有「从节点」修改复制目标，修改为复制「新主节点」；
        当新主节点出现之后，哨兵 leader 下一步要做的就是，让已下线主节点属下的所有「从节点」指向「新主节点」，这一动作可以通过向「从节点」发送 SLAVEOF 命令来实现。

    第三步：将新主节点的 IP 地址和信息，通过「发布者/订阅者机制」通知给客户端；

        通过 Redis 的发布者/订阅者机制来实现。主从切换完成后，哨兵就会向 +switch-master 频道发布新主节点的 IP 地址和端口的消息，这个时候客户端就可以收到这条信息，然后用这里面的新主节点的 IP 地址和端口进行通信了。

    第四步：继续监视旧主节点，当这个旧主节点重新上线时，将它设置为新主节点的从节点；


| 事件 | 
|---|
| +sdown(实例进入“主观下线”状态) | **sentinel** |
| -sdown(实例退出“主观下线”状态) | **sentinel** |
| todown(实例进入“客观下线”状态) | **sentinel** |
| -odown(实例退出“客观下线”状态) | **sentinel** |
| +slave-reconf-sent(哨兵发送SLAVEOF命令重新配置从库) | **sentinel** |
| +slave-reconf-inprog(从库配置了新主库,但尚未进行同步) | **sentinel** |
| +slave-reconf-done(从库配置了新主库,且和新主库完成同步) | **sentinel** |
| +switch-master(主库地址发生变化) | **sentinel** |



## 集群
集群就是多个Redis一起对外提供服务，对外看起来就像是一个单机服务的解决方案。

`cluster-enabled`，设置为yes，这样才能成为集群的一份子  
`cluster meet`可以连接上其它节点  
`cluster addslot`为每个节点，划分Hash槽
`cluster nodes`可以查看连接状况  

### Hash slot
一个 Redis Cluster包含16384个哈希槽，存储在Redis Cluster中的所有Key都可以通过Hash算法关联到某个槽，而每个节点负责一部分槽，Key算出来在哪个槽，就应该去负责这个槽的节点进行交互。在分配槽之后，节点会向集群中其它节点放送消息，告知它负责了哪些槽。

Redis用slots表示了整个hash槽空间(16384个槽)，这个数组以位图的方式会记录每个槽的状态，如果是1，则表示是自己负责的。

## 其他
主从复制架构中，过期key如何处理？
主节点处理了一个key或者通过淘汰算法淘汰了一个key，这个时间主节点模拟一条del命令发送给从节点，从节点收到该命令后，就进行删除key的操作。



##
Redis集群中的消息类型

新节点收到MEET消息后会回复一个PONG消息

接收者收到PING消息后会回复一个PONG消息

故障恢复后新的主节点会广播PONG消息

节点收到PUBLISH命令后，会先执行该命令，然后向集群广播这一消息